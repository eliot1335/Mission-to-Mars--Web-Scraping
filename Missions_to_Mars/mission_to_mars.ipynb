{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('dv_u12_pip': conda)",
   "metadata": {
    "interpreter": {
     "hash": "686725e5a10d5481ff770f2e0a0bb85e39a17c2396e44466ecd3f149ddd73f40"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[WDM] - Current google-chrome version is 87.0.4280\n",
      "[WDM] - Get LATEST driver version for 87.0.4280\n",
      "[WDM] - Driver [C:\\Users\\eliot\\.wdm\\drivers\\chromedriver\\win32\\87.0.4280.88\\chromedriver.exe] found in cache\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Setup splinter\n",
    "executable_path = {\"executable_path\": ChromeDriverManager().install()}\n",
    "browser = Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "source": [
    "## NASA Mars News"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the NASA Mars News Site and collect the latest News Title and Pragraph Text\n",
    "# Assign the text the variables that I can reference later\n",
    "\n",
    "# The url to scrae, NASA Mars News Site\n",
    "url = \"https://mars.nasa.gov/news/\"\n",
    "\n",
    "browser.visit(url)\n",
    "html = browser.html\n",
    "\n",
    "\n",
    "# print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Beautiful Soup object\n",
    "soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'NASA to Host Virtual Briefing on February Perseverance Mars Rover Landing'"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# Scrape latest news, get title and paragraph\n",
    "# Search for div and class=content_title\n",
    "titles = soup.find_all(\"div\", class_=\"content_title\")\n",
    "# news_titles\n",
    "\n",
    "# A blank list to hold titles\n",
    "news_titles = []\n",
    "# Loop over results\n",
    "for news_title in titles:\n",
    "    # Check if it has an anchor...\n",
    "    if (news_title.a):\n",
    "        # Check if it has non-blank text...\n",
    "        if (news_title.a.text):\n",
    "            # Strip it for text and push to list\n",
    "            news_titles.append(news_title.a.text.strip())\n",
    "\n",
    "latest_news_title = news_titles[0]\n",
    "latest_news_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'NASA leadership and members of the mission will discuss the agencyâ€™s latest rover, which touches down on the Red Planet on Feb. 18.'"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# Get paragraph\n",
    "# article_teaser_body don't have an anchor\n",
    "paragraphs = soup.find_all(\"div\", class_=\"article_teaser_body\")\n",
    "\n",
    "# A blank list to hold teaser paragraphs\n",
    "news_paragraphs = []\n",
    "\n",
    "for news_paragraph in paragraphs:\n",
    "    # Check if it has non-blank text...\n",
    "    if (news_paragraph.text):\n",
    "        # Strip it for text and push to list\n",
    "        news_paragraphs.append(news_paragraph.text.strip())\n",
    "\n",
    "latest_news_paragraph = news_paragraphs[0]\n",
    "latest_news_paragraph\n"
   ]
  },
  {
   "source": [
    "## JPL Mars Space Images - Featured Image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "given_url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "browser.visit(given_url)\n",
    "browser.click_link_by_partial_href(\"/images/daedalia-planum-70/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://d2pn8kiwq2w21t.cloudfront.net/images/jpegPIA24367.width-1024.jpg\n"
     ]
    }
   ],
   "source": [
    "soup = bs(html, \"html.parser\")\n",
    "\n",
    "images = soup.find_all(\"img\", class_=\"BaseImage object-scale-down\")\n",
    "for image in images:\n",
    "    print(image[\"src\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# # Find the image url for the current Featured Mars Image and assign the url to featured_image_url\n",
    "# # The url to scrae,  JPL Featured Space Image\n",
    "# url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "\n",
    "# browser.visit(url)\n",
    "# html = browser.html\n",
    "print(featured_img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a Beautiful Soup object\n",
    "# soup = bs(html, \"html.parser\")"
   ]
  }
 ]
}